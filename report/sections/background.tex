\section{Methods}

The few-shot learning algorithms considered can broadly be categorised into two paradigms of learning: \textit{transfer learning} and \textit{meta-learning}.
 
In transfer learning, a model learns a direct mapping from input features to the target labels on a related task during a pre-training phase and then adapts the weights of the model to the task at hand in a fine-tuning phase. An example of such an algorithm is the Baseline method~\cite{baseline}.

In contrast, meta-learning algorithms learn a mapping from input features to a latent space where samples from the same class are close to each other. This latent space is then used to classify new samples. All remaining methods in our study are meta-learning algorithms, and can be further divided into metric-based~\cite{matchingnet, protonet} and optimization-based methods~\cite{maml}. During meta-training of such algorithms, the model is presented with a set of tasks (called episodes) which resemble the few-shot learning task at hand. The goal is to learn a model that can quickly adapt to new tasks. 
% TODO: Explain meta-training/ meta-testing (in contrast to regular training and testing)

Meta-learning algorithms can generally be differentiated into \textit{inductive} and \textit{transductive} methods. Transductive methods use information about the query samples during training, while inductive methods do not. This differentiation will be important in our discussion about the effect of the SOT feature transform on the different methods.

Our study considers four prominent few-shot learning algorithms from the literature: Baseline(++)~\cite{baseline}, Matching Networks~\cite{matchingnet}, Prototypical Networks~\cite{protonet}, and Model-Agnostic Meta-Learning (MAML)~\cite{maml}, each of which is described in more detail below. We then describe the SOT feature transform~\cite{sot} and how it is used to enhance the performance of the few-shot learning algorithms.

% use as part of their adaption process query samples' features. This is indeed possible only in meta learning setting where we have access to the features of the samples we later evaluate our model on, in contrast to the classical batch learning.

% aims to teach the model to be able to learn quickly. Therefore, during the training, in each epoch, the model is presented with the given number of episodes where each episode can be viewed as a different task. Given that in our work, we solely focus on classification, each episode consists of the given number of classes (\texttt{n-way}) where for each class we have certain number of support samples (\texttt{n-shot}) and query samples. During inference, the model is evaluated on its ability to adapt to newly presented tasks.  It first uses the support vectors from the episode to adapt to the task at hand and then its performance is evaluated based on the query samples. The final performance of a model is a mean score across all episodes which should reflect its ability to adapt quickly to new tasks, even with a small amount of samples.
 
% The methods presented in our work use two types of learning. In supervised learning, the objective of the model is to learn the general mapping from the observed samples seen during training to the given task and then be able to apply this knowledge on unseen samples during inference. However, in practice, there is often a need to use the model on a slightly different task than it was initially trained on. One possible solution is to fine tune the model on the subset of data for the new task. This, however, depending on the difficulty of the task might require large amount of labeled data. 
% 
% This motivated research in meta learning where the focus is towards teaching the model to be able to learn quickly. Therefore, during the training, in each epoch, the model is presented with the given number of episodes where each episode can be viewed as a different task. Given that in our work, we solely focus on classification, each episode consists of the given number of classes (\texttt{n-way}) where for each class we have certain number of support samples (\texttt{n-shot}) and query samples. During inference, the model is evaluated on its ability to adapt to newly presented tasks.  It first uses the support vectors from the episode to adapt to the task at hand and then its performance is evaluated based on the query samples. The final performance of a model is a mean score across all episodes which should reflect its ability to adapt quickly to new tasks, even with a small amount of samples.

\subsection{Baseline}

On the other hand, the recently proposed Baseline method is trained conventionally in a supervised manner. During inference, however, a new classification head is initialized from scratch and fine-tuned using stochastic gradient  descent on the provided support vectors. In the classical Baseline configuration, the classification head is a single linear layer. However, there is also an alternative configuration, where the classification head is a cosine similarity layer in which for each class, we have a trainable class prototype. The cosine similarity layer then computes the cosine similarity between the query sample and each class prototype.

\subsection{Prototypical Networks}

Prototypical Network~\cite{protonet} (\texttt{ProtoNet}) is a metric based meta-learning approach that first aggregates support samples within each class to create class prototypes. We then compare query samples to each of the respective class prototypes and assign the query to the closest prototype.

\subsection{Matching Networks}

In contrast, Matching Network~\cite{matchingnet} (\texttt{MatchingNet}) employs pairwise comparisons, comparing the query sample to all support samples for each class. In addition, \texttt{MatchingNet} includes further transformation of both support and query samples. The support embeddings are contextualised via a bidirectional Long-Short-Term Memory network (LSTM). These are then compared to every query embedding via a cosine distance to determine how much much weight should be each support vector given when constructing the new version of query embedding. The final step involves contextualizing query embeddings through multiple iterations in a single LSTM Cell. Overall, these steps aim to enhance \texttt{MatchingNet}'s discriminative power for improved classification performance.

\subsection{Model Agnostic Meta Learning (MAML)}

Finally, Model Agnostic Meta Learning~\cite{maml} (\texttt{MAML}) is a optimisation-based meta-learning approach that aims to learn an effective weight initialisation that can be adapted to new tasks in a small number of gradient steps. During meta-training the model is presented with a set of tasks $\mathcal{T}_1, ..., \mathcal{T}_n$ (episodes) each containg a support set $\mathcal{D}_i^{tr}$ and querys et $\mathcal{D}_i^{te}$. For each task, a model is initialised from a shared initialisation and then adapted to the task at hand. After a number of steps the global parameters are updated based on the sum of 
losses computed on the query samples of all tasks. The update rule can thus be described as follows:
$$
\theta = 
\theta - \beta \nabla_{\theta} \sum_{i=1}^{n}
\mathcal{L}(\theta - \alpha \nabla_{\theta} \mathcal{L}(\theta, \mathcal{D}_{i}^{tr}), \mathcal{D}_{i}^{ts})
$$

% takes in contrast to the previous two methods metric driven approach. \texttt{MAML} focuses on learning an effective initialization of weights during training. Specifically, there are two kinds of weights in \texttt{MAML}. Slow weights are regular model weights which are being updated after a predefined number of episodes. Conversely, fast weights are initialised from the existing slow weights for each episode, and then based on episode's support samples, the fast weights are adapted for a predefined number of steps. After the adaptation procedure, the loss computed based on model's prediction on episodes' query samples is computed. This is repeated for predefined number of episodes after which the slow weights are updated based on query samples loss.


% The primary strategies for few-shot classification can be categorised into two approaches. The first involves training a classifier from scratch or adapting pre-trained models through fine-tuning. This approach is exemplified by Model-Agnostic Meta-Learning (MAML)~\cite{maml}, which extends beyond basic fine-tuning by integrating a meta-training phase. This phase is designed to optimise weight initialisation, such that the model can generalise well to any downstream few-shot classification task.

% The second category encompasses metric-based methods, which focus on learning discriminative embeddings through meta-learning. Unlike the first approach, these methods do not directly map features to targets. Instead, they use the learned embeddings to classify new instances based on simple distance-based heuristics. Notable methods in this category include Matching Networks~\cite{matchingnet} and Prototypical Networks (ProtoNet)~\cite{protonet}.



\subsection{Self-Optimal Transport}

% Outline
% 0. High level: 
% In the second phase of our benchmark study, we enhance each method with a Self-Optimal-Transport (SOT) feature transform module \cite{sot}  to explore its potential in improving overall classification performance.  SOT, operating through pair-wise cosine distance computations, works towards alignment of a given sample with the most similar  samples in the dataset. Consequently, samples from the same class should ideally exhibit similar embeddings, thereby facilitating  subsequent classification. By definition, this effect is particularly advantageous for distance metric-based methods.
% 1. Cost matrix computation
% 2. Sinkhorn 
% The \textbf{Sinkhorn algorithm} is used. It is an iterative procedure that adjusts the elements of a matrix to make its rows and columns sum up to specified target vectors (usually probability distributions). We used a variant that operates in log space for improved numerical stability, especially when dealing with very small or very large numbers. 
% 3. Important properties - explanatibility, direct and indirect comparison

In the second phase of our benchmark study, we enhance each method with the Self-optimal transport (SOT) feature transform~\cite{sot}. This method is used to transform features produced by the backbone. Each new embedded feature vector created by the SOT encodes similarities to all other feature vectors, thereby improving the performance of the classifier.  At its core, SOT employs an \textbf{Optimal Transport (OT)}, which is a mathematical theory for efficiently transforming one probability distribution into another. 

The feature set $V$ containing $n$ vectors of dimension $d$ is re-embedded using a transform $T$, to obtain a new set of features $W = T(V)$, where $W \in \mathbb{R}^{n \times n}$. The proposed transform $T: \mathbb{R}^{n \times d} \rightarrow \mathbb{R}^{n \times n}$ acts on the original feature set \( V \) as follows. It begins by computing the squared cosine pairwise distances matrix $D$. $W$ will be computed as the optimal transport plan matrix between the $n$-dimensional all-ones vector $\mathbf{1}_n$ and itself, under the cost matrix $D_{\infty}$, which is the distance matrix $D$  with a very large scalar $\alpha$ replacing each of the entries on its diagonal. We used $\alpha=1000$ as it was the constant the authors of SOT also used.

\( W \) is defined to be the doubly-stochastic matrix, that is the minimizes Frobenius dot-product between $D_{\infty}$ and $W$. To compute $W$, authors use the highly efficient \textbf{Sinkhorn-Knopp} method, which is an iterative scheme that optimizes an entropy-regularized version of the problem, where each iteration takes $\Theta(n^2)$. We used $10$ Sinkhorn iterations as it was also used by the authors.

The transport-plan matrix $W$ is the result of the transform, the final set of features $W$ is obtained by replacing the diagonal entries from $0$s to $1$s. Each row is the re-embedding of the corresponding row in $V$. $W$ is doubly stochastic and symmetric.

In the $i$-th feature vector, the $j$-th value represents the relative belief that feature vectors $i$ and $j$ belong to the same `class'. The reason behind this interpretation falls outside the scope of this paper. However, for a more comprehensive understanding and further details, please refer to the original paper \cite{sot}.

An important property of the SOT embedding is that by comparing embedded vectors $w_i$ and $w_j$ we acquire both direct and indirect information about the similarity between the features. This can be seen if we look at the different coordinates $k$ of the absolute difference vector $a=|w_i - w_j|$. When $k\in\{i,j\}$, we have $a_k = 1 - w_{ij} = 1 - w_{ji}$. If \( a_k \) is small, it means the features are directly similar.

When $k \notin \{i,j\}$, we have $a_k = |wik - wjk|$. If $a_k$ is small it means that features $i$ and $j$ have similar beliefs or relationships with feature $k$. They are indirectly similar through their common relationship with the $k$-th feature vector.

Other perks of this method are parameterless-ness, differentiability, equivariance to permutation of the features, and explainability. On the other hand, the fact that the output dimension depends on (is equal to) the number of feature vectors causes problems when the downstream calculation that follows the feature embedding expects a fixed input size.