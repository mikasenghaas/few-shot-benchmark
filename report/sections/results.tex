\section{Results}


Figure~\ref{fig:benchmark-perf} and Table \ref{tab:tuned-benchmark} shows the test accuracies for each method with and without the SOT module on both datasets. 

% Without SOT:
% TM: (91.3 + 81.7 + 89.8 + 85 + 90)/5 = 87.56
% SP: (69.5 + 56.4 + 58.7 + 61.6 + 61.4)/5 = 61.52
Models without the SOT module reach an average accuracy of 87\% on the \texttt{TM} dataset and 61\% on the \texttt{SP} dataset. These results generally show that the models are capable of learning from few samples, improving significantly over the random baseline of 20\% accuracy. Furthermore, the \texttt{SP} dataset seems more challenging than the \texttt{TM} dataset. Notably, \texttt{B} outperforms all others in both datasets, whereas \texttt{B++} ranks lowest.

% With SOT:
% TM: (86.4 + 81.9 + 87.1 + 89.6 + 89.1)/5 = 86.42
% SP: (55.8 + 65.8 + 64.9 + 68 + 66.4)/5 = 64.58
Models with the SOT module yield an average accuracy of 86\% on the \texttt{TM} dataset and 65\% on the \texttt{SP} dataset, showing slight variations from non-SOT results. Performance impacts vary among methods: Meta-learners \texttt{MN}, \texttt{PT}, and \texttt{MAML} improve on \texttt{SP} with SOT, but \texttt{B}'s performance decreases. \texttt{MN}, with SOT, excels in both datasets, reaching the highest accuracy of 89\% on \texttt{TM} and 68\% on \texttt{SP}.

\textbf{Hyperparameter Ablation.} Figure~\ref{fig:hparams-swissprot-grid} shows the pair-wise interactions between all tuned hyper-parameters, methods and the inclusion of the SOT module on the \texttt{SP} data. 

% TODO: Include section about ablation of tuned hyper-parameters

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\columnwidth]{figures/hparams-swissprot-grid.pdf}
    \caption{\textbf{Hyperparameter Ablation.} Test accuracies on the \texttt{SP} dataset for all pairs of hyperparameter settings.}
    \label{fig:hparams-swissprot-grid}
\end{figure}

\input{tables/tuned-benchmark.tex}

\textbf{Way-Shot Analysis.} Figure~\ref{fig:way-shot} illustrates \texttt{PN}'s way-shot analysis on the TM dataset, comparing scenarios with and without the SOT module. The left subplot depicts test accuracy versus the number of classes (ways), while the right subplot relates accuracy to the number of samples per class (shots). In both SOT and non-SOT contexts, a consistent trend emerges: accuracy diminishes linearly with more classes and grows concavely with additional samples per class. Notably, exceeding five samples per class yields no substantial accuracy gains. The model's performance with the SOT module is inferior for higher numbers of classes and samples.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\columnwidth]{figures/way-shot.pdf}
    \caption{\textbf{Way-Shot Analysis.} Test accuracy of \texttt{PN} on the \texttt{TM} dataset with and without the SOT module in various 
    few-shot learning settings for fixed n-way (left) and n-shot (right). Individual points represent a single experiment. We show the regression line with a 95\% confidence interval.}
    \label{fig:way-shot}
\end{figure}
