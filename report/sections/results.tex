\section{Results}
Table \ref{tab:tuned-benchmark} displays the results of the first part of 
our benchmark study. We fine-tuned hyper-parameters of each method on the given dataset and 
then evaluated it across 600 episodes. The table presents the mean accuracy,
 accompanied by a 95\% confidence interval across the episodes. 
 The \texttt{Diff} column indicates the change in mean accuracy when we 
 introduce the \texttt{SOT} module to the method.

Firstly, we observe that for the 5-way, 5-shot setting, all methods without 
\texttt{SOT} already reach an average accuracy of 87\% for the \texttt{TM} 
dataset and 66\% for the \texttt{SP} dataset, establishing a very solid baseline performance.
Secondly, we notice that the presence of the \texttt{SOT} module enhances all 
methods except for the Baseline. However, for \texttt{B++}, the performance improvement is only marginal. 
In contrast, for the remaining three methods, \texttt{SOT} improved the performance for the \texttt{TM} dataset 
by an average of 12\% and by 48\% for the \texttt{SP} dataset. 
Therefore, for both datasets, we observe a substantial effect size after the integration of the \texttt{SOT} module.

\input{tables/tuned-benchmark.tex}