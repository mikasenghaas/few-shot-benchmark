\begin{abstract}
    Our study rigorously evaluates prominent few-shot learning algorithms, including Baseline, Matching Networks, Prototypical Networks, and MAML, in two few-shot classification tasks based on the Tabula Muris and SwissProt datasets. All algorithms demonstrate substantial efficacy, with the best performing algorithms achieving 69.1\% and 91.3\% accuracy on the SwissProt and Tabula Muris datasets, respectively. Additionally, we found that incorporating the Self-Optimal Transport (SOT) feature transform module enhances performance in most settings with minimal computational overhead, increasing the best performance to 70.9\% (+1,8) and 93.5\% (+2,2) on the \nobreak{SwissProt} and Tabula Muris datasets, respectively. \textit{The code and experiments are available on \href{https://github.com/mikasenghaas/few-shot-benchmark}{GitHub} and \href{https://wandb.ai/metameta-learners/few-shot-benchmark}{W\&B}.}
\end{abstract}