{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "This notebook contains the analysis of the data tracked on\n",
    "[Weights & Biases](https://wandb.ai/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bult-in modules\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# External modules\n",
    "# - Data Representation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# - Data Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# - Machine Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "\n",
    "# - Experiment Configuration and Logging\n",
    "import wandb\n",
    "\n",
    "# Custom modules\n",
    "from utils import eval_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of global variables\n",
    "WANDB_PROJECT = \"few-shot-benchmark\"\n",
    "WANDB_ENTITY = \"metameta-learners\"\n",
    "\n",
    "GROUP = \"mika\"\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\".\"))\n",
    "ARTIFACT_DIR = os.path.join(ROOT_DIR, \"artifacts\")\n",
    "FIGURE_DIR = os.path.join(ROOT_DIR, \"figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Experiment Data\n",
    "\n",
    "---\n",
    "\n",
    "Let's start by loading all runs from the given experiment group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 runs\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Get all runs\n",
    "runs = api.runs(f\"{WANDB_ENTITY}/{WANDB_PROJECT}\")\n",
    "\n",
    "# Filter runs by group\n",
    "group_runs = [run for run in runs if run.group == GROUP]\n",
    "print(f\"Found {len(group_runs)} runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load all runs from the given experiment group into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">config</th>\n",
       "      <th colspan=\"10\" halign=\"left\">eval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>sot</th>\n",
       "      <th>n_way</th>\n",
       "      <th>n_shot</th>\n",
       "      <th>val/acc_std</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val/acc</th>\n",
       "      <th>test/acc</th>\n",
       "      <th>val/acc_ci</th>\n",
       "      <th>test/acc_ci</th>\n",
       "      <th>train/acc</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>test/acc_std</th>\n",
       "      <th>train/acc_ci</th>\n",
       "      <th>train/acc_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cmmdjbv0</th>\n",
       "      <td>swissprot</td>\n",
       "      <td>baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11.659457</td>\n",
       "      <td>3</td>\n",
       "      <td>71.480000</td>\n",
       "      <td>68.633333</td>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.910922</td>\n",
       "      <td>87.78</td>\n",
       "      <td>1.161866</td>\n",
       "      <td>11.384151</td>\n",
       "      <td>0.665911</td>\n",
       "      <td>8.322155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rjejahjj</th>\n",
       "      <td>swissprot</td>\n",
       "      <td>baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11.756795</td>\n",
       "      <td>3</td>\n",
       "      <td>71.866667</td>\n",
       "      <td>68.066667</td>\n",
       "      <td>0.940740</td>\n",
       "      <td>0.886208</td>\n",
       "      <td>88.36</td>\n",
       "      <td>1.161866</td>\n",
       "      <td>11.075298</td>\n",
       "      <td>0.630342</td>\n",
       "      <td>7.877631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             config                                            eval  \\\n",
       "            dataset    method    sot n_way n_shot val/acc_std epoch   \n",
       "run_id                                                                \n",
       "cmmdjbv0  swissprot  baseline  False     5      5   11.659457     3   \n",
       "rjejahjj  swissprot  baseline  False     5      5   11.756795     3   \n",
       "\n",
       "                                                                            \\\n",
       "            val/acc   test/acc val/acc_ci test/acc_ci train/acc train/loss   \n",
       "run_id                                                                       \n",
       "cmmdjbv0  71.480000  68.633333   0.932951    0.910922     87.78   1.161866   \n",
       "rjejahjj  71.866667  68.066667   0.940740    0.886208     88.36   1.161866   \n",
       "\n",
       "                                                  \n",
       "         test/acc_std train/acc_ci train/acc_std  \n",
       "run_id                                            \n",
       "cmmdjbv0    11.384151     0.665911      8.322155  \n",
       "rjejahjj    11.075298     0.630342      7.877631  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_runs = utils.load_to_df(group_runs)\n",
    "df_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking closer to particular runs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a run from the table above to look at it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = 'cmmdjbv0'\n",
    "config = [run.config for run in group_runs if run.id == runid][0]\n",
    "dataset, loader, model = utils.init_run(config, ROOT_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's evaluate the run's model on the given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [00:07<00:00,  3.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.555960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.710909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.374921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.735198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.756667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score\n",
       "0            0.56         0.560000          0.56  0.555960\n",
       "1            0.72         0.720000          0.72  0.710909\n",
       "2            0.40         0.390000          0.40  0.374921\n",
       "3            0.76         0.833333          0.76  0.735198\n",
       "4            0.76         0.782857          0.76  0.756667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mapping from encoding to annotation\n",
    "encoding2anot = {v : k for k, v in dataset.trg2idx.items()}\n",
    "\n",
    "# Define metric fn from sklearn assuming y_true and y_pred as input in this order\n",
    "clf_kwargs = {\"average\": \"macro\"}\n",
    "metric_fns = [\n",
    "    (metrics.accuracy_score, None),\n",
    "    (metrics.precision_score, clf_kwargs),\n",
    "    (metrics.recall_score, clf_kwargs),\n",
    "    (metrics.f1_score, clf_kwargs),\n",
    "]\n",
    "\n",
    "# Evaluate model and obtain its predictions with ground truth for each episode\n",
    "episodes_results = utils.eval_run(model, loader)\n",
    "\n",
    "# Compute metrics for each episode\n",
    "episodes_metrics = utils.compute_metrics(metric_fns, episodes_results)\n",
    "\n",
    "episodes_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "few-shot-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
