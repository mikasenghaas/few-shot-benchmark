{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:29:32.471082Z",
     "start_time": "2023-11-24T21:29:32.466504Z"
    }
   },
   "id": "f443c36fb1901cb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backbones\n",
    "\n",
    "Backbones are used as the feature extractor in the meta template. In the folder `backbones` there are several backbones implemented for us. The most basic one is the `FCNet` which is a fully connected network. The other backbones are `ConvNet` and `ResNet` which are convolutional neural networks. Let's explore them one by one."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74d93fa29cb4f313"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fully connected network\n",
    "\n",
    "`FCNet` is a fully connected network with parameters \n",
    "- `x_dim` which is the dimension of the input\n",
    "- `layer_dim` which is a list of integers that specifies dimensions of the hidden layers\n",
    "- `dropout` which is the dropout rate\n",
    "- `fast_weights` which is a boolean that specifies whether to use fast weights. This will be the case for all backbones and it is connected to MAML model (see [methods](methods.ipynb)). See [Fast weights](#fast-weights) for more details.\n",
    "\n",
    "One block of `FCNet` is defined in the function `full_block`  in `backbones/blocks.py`. It consists of a linear layer, a batch normalization layer, a ReLU layer and a dropout layer.\n",
    "\n",
    "Number of blocks is defined by numeber of elements in `layer_dim`. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "743e7ca8b0759504"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNet(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from backbones.fcnet import FCNet\n",
    "\n",
    "model = FCNet(x_dim=32, layer_dim=[64,64])\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:15:50.236242Z",
     "start_time": "2023-11-24T21:15:50.233816Z"
    }
   },
   "id": "7b65ee52848f6dd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Changing the backbone"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e39574198859c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Changes to the original code\n",
    "\n",
    "1. I includend `**kwargs` in the `__init__` function of the backbones to make the `run.py` script work with the backbones other than `FCNet`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13cdc74506079529"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fast Weights\n",
    "\n",
    "Fast weights in backbones facilitate easier implementation of MAML algorithm. The idea is that we have two sets of weights in the model: the initial weights and the fast weights. The initial weights are the ones that are updated in the outer loop of the MAML algorithm. The fast weights are the ones that are updated in the inner loop of the MAML algorithm. The fast weights are only temporary for one episode. This way we can use the same model for both inner and outer loops.\n",
    "\n",
    "### Fast Weights in MAML\n",
    "![MAML for multiple tasks](../images/maml_pseudocode.png)\n",
    "\n",
    "MAML operates on a two-level learning process:\n",
    "- The **inner loop** uses fast weights for quick task-specific adaptation.\n",
    "- The **outer loop** updates the \"slow\" (initial) weights, improving the model's generalization across tasks.\n",
    "\n",
    "### Inner Loop\n",
    "- **Evaluation (Line 5)**: For each task $\\mathcal{T}_i$, the algorithm evaluates the gradient of the loss function $\\mathcal{L}_{\\mathcal{T}_i}$ with respect to the initial parameters $\\theta$ using a small subset of $K$ examples. This gradient tells us how to update the parameters to improve performance on this task.\n",
    "- **Compute Adapted Parameters (Line 6)**: The fast weights $\\theta_i'$ are computed by adjusting the initial parameters $\\theta$ using the evaluated gradient. The step size hyperparameter $\\alpha$ determines how big of a step to take in the direction of the gradient. This creates a new set of parameters that are adapted specifically for task $\\mathcal{T}_i$, and these adapted parameters are what we refer to as \"fast weights\". They are fast in the sense that they are rapidly computed based on just a few examples from the current task and are discarded after use.\n",
    "\n",
    "### Outer Loop\n",
    "After processing each task in the batch, the initial parameters $\\theta$ are updated. This update is based on the sum of the gradients of the loss function $\\mathcal{L}_{\\mathcal{T}_i}$ with respect to the fast weights $\\theta_i'$ for each task in the batch. The step size hyperparameter $\\beta$ controls the size of this update. The updated $\\theta$ will be a better starting point for new tasks, hence improving the model's ability to adapt to new tasks quickly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ed7e46f9017a2a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "248807fe9d677b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
